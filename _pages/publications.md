---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---
<div class="pubwrap">
      <div class="row">
        <div class="col-md-4">
          <div class="pubimg">
            <img src="./Yen-Chen Lin Website_files/adversarial_attack_RL.gif" height="100" width="250">
          </div>
        </div>
        <div class="col-md-8">
          <div class="pub">
            <div class="pubt">Tactics for Adversarial Attack on Deep Reinforcement Learning Agents</div>
            <!--
            <div class="pubd">We introduce two tactics to attack agents trained by deep reinforcement learning algorithms using adversarial examples:
Strategically-timed attack: the adversary aims at minimizing the agent's reward by only attacking the agent at a small subset of time steps in an episode.
Enchanting attack: the adversary aims at luring the agent to a designated target state.</div>
            -->
            <div class="puba"><u>Yen-Chen Lin</u>, Zhang-Wei Hong, Yuan-Hong Liao, Meng-Li Shih, Ming-Yu Liu, Min Sun</div>
            <div class="pubv">IJCAI 2017</div>
            <a href="http://yclin.me/adversarial_attack_RL">[project]</a>
            <a href="https://arxiv.org/abs/1703.06748">[arXiv]</a>
            </div>
          </div>
        </div>
      </div>
</div>

